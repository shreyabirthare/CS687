{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_STATE = (0,0)\n",
    "FOOD_STATE = (4,4)\n",
    "ACTIONS = [(0,-1), (0,1), (-1,0), (1,0)]\n",
    "p={}\n",
    "p['specified'] = 0.7\n",
    "p['right'] = 0.12\n",
    "p['left'] = 0.12\n",
    "p['sleepy'] = 0.06\n",
    "FORBIDDEN_FURNITURES = [(2,1), (2,2), (2,3), (3,2)]\n",
    "MONSTERS = [(0,3), (4,1)]\n",
    "DELTA = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTransitionProbabilities(action, p):\n",
    "    if action == (0, -1):\n",
    "        specified = (0, -1)\n",
    "        left = (1, 0)\n",
    "        right = (-1, 0)\n",
    "    elif action == (0, 1):\n",
    "        specified = (0, 1)\n",
    "        left = (-1, 0)\n",
    "        right = (1, 0)\n",
    "    elif action == (-1, 0):\n",
    "        specified = (-1, 0)\n",
    "        left = (0, -1)\n",
    "        right = (0, 1)\n",
    "    else:\n",
    "        specified = (1, 0)\n",
    "        left = (0, 1)\n",
    "        right = (0, -1)\n",
    "\n",
    "    sleepy = (0, 0)\n",
    "    return [(specified, p['specified']), (left, p['left']), (right, p['right']), (sleepy, p['sleepy'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getReward(to_state, isCatnip=False, isCatnipTerminal = False, checkDiffRewards = (False, None)):\n",
    "    if to_state == FOOD_STATE:\n",
    "        return 10\n",
    "    elif to_state in MONSTERS:\n",
    "        return -8\n",
    "    elif (isCatnip or isCatnipTerminal) and to_state == (0, 1):\n",
    "        return 5\n",
    "    elif (checkDiffRewards[0] and to_state == (0,1)):\n",
    "        return checkDiffRewards[1]\n",
    "    else:\n",
    "        return -0.05\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isValidState(i, j):\n",
    "    if i < 0 or j < 0 or i >= 5 or j >= 5:\n",
    "        return False\n",
    "    if (i, j) in FORBIDDEN_FURNITURES:\n",
    "        return False\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runValueIterationAlgo(gamma, theta=DELTA, isCatnip=False, isCatnipTerminal=False, checkDiffRewards = (False, None)):\n",
    "    value_mat = np.zeros((5, 5))\n",
    "    policy_mat = np.full((5, 5), None)\n",
    "    count = 0\n",
    "    while True:\n",
    "        count +=1\n",
    "        delta = 0\n",
    "        new_value_mat = np.copy(value_mat)\n",
    "\n",
    "        for i in range(5):\n",
    "            for j in range(5):\n",
    "                if (i, j) in FORBIDDEN_FURNITURES or (i, j) == FOOD_STATE or (isCatnipTerminal and (i, j) == (0, 1)):\n",
    "                    continue\n",
    "\n",
    "                best_action = None\n",
    "                best_value = float('-inf')\n",
    "\n",
    "                for action in ACTIONS:\n",
    "                    transitions = getTransitionProbabilities(action, p) #[(), ()]\n",
    "                    value = 0\n",
    "\n",
    "                    for next_state, prob in transitions:\n",
    "                        next_i, next_j = i + next_state[0], j + next_state[1]\n",
    "\n",
    "                        if not isValidState(next_i, next_j):\n",
    "                            next_i = i\n",
    "                            next_j = j\n",
    "\n",
    "                        reward = getReward((next_i, next_j), isCatnip, isCatnipTerminal, checkDiffRewards)  # Adjust for Catnip if needed\n",
    "                        value += prob * (reward + gamma * value_mat[next_i, next_j])\n",
    "\n",
    "                    if value > best_value:\n",
    "                        best_value = value\n",
    "                        best_action = action\n",
    "\n",
    "                new_value_mat[i, j] = best_value\n",
    "                policy_mat[i, j] = best_action\n",
    "\n",
    "                delta = max(delta, abs(value_mat[i, j] - new_value_mat[i, j]))\n",
    "\n",
    "        value_mat = new_value_mat  # Update value matrix\n",
    "        if delta < theta:  # Check for convergence\n",
    "            break\n",
    "\n",
    "    return value_mat, policy_mat, count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runValueIterationInPlace(gamma, theta=DELTA, isCatnip=False, isCatnipTerminal=False):\n",
    "    value_mat = np.zeros((5, 5))\n",
    "    policy_mat = np.full((5, 5), None)\n",
    "    count = 0\n",
    "    while True:\n",
    "        count += 1\n",
    "        delta = 0\n",
    "\n",
    "        for i in range(5):\n",
    "            for j in range(5):\n",
    "                if (i, j) in FORBIDDEN_FURNITURES or (i, j) == FOOD_STATE or (isCatnipTerminal and (i, j) == (0, 1)):\n",
    "                    continue\n",
    "\n",
    "                best_action = None\n",
    "                best_value = float('-inf')\n",
    "\n",
    "                for action in ACTIONS:\n",
    "                    transitions = getTransitionProbabilities(action, p)\n",
    "                    value = 0\n",
    "\n",
    "                    for next_state, prob in transitions:\n",
    "                        next_i, next_j = i + next_state[0], j + next_state[1]\n",
    "\n",
    "                        if not isValidState(next_i, next_j):\n",
    "                            next_i = i\n",
    "                            next_j = j\n",
    "\n",
    "                        temp_reward = getReward((next_i, next_j), isCatnip, isCatnipTerminal)\n",
    "                        value += prob * (temp_reward + gamma * value_mat[next_i, next_j])\n",
    "\n",
    "                    if value > best_value:\n",
    "                        best_value = value\n",
    "                        best_action = action\n",
    "\n",
    "                # Update the value_mat directly\n",
    "                delta = max(delta, abs(value_mat[i, j] - best_value))\n",
    "                value_mat[i, j] = best_value\n",
    "                policy_mat[i, j] = best_action\n",
    "\n",
    "        if delta < theta:\n",
    "            break\n",
    "\n",
    "    return value_mat, policy_mat, count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printPolicyMat(policy_mat, isCatnipTerminal=False):\n",
    "    action_to_arrow = {\n",
    "        (0, -1): '←',  # Left\n",
    "        (0, 1): '→',   # Right\n",
    "        (-1, 0): '↑',   # Up\n",
    "        (1, 0): '↓'     # Down\n",
    "    }\n",
    "    result = []\n",
    "    \n",
    "    for i in range(5):\n",
    "        row = []\n",
    "        for j in range(5):\n",
    "            state = (i, j)\n",
    "            if state in FORBIDDEN_FURNITURES:\n",
    "                symbol = \"X\"\n",
    "            elif state in MONSTERS:\n",
    "                action = policy_mat[i][j]\n",
    "                symbol = f\"{action_to_arrow.get(action, ' ')}ᴹ\"\n",
    "            elif state == FOOD_STATE or (isCatnipTerminal and state == (0,1)):\n",
    "                symbol = \"G\"\n",
    "            else:\n",
    "                action = policy_mat[i][j]\n",
    "                symbol = action_to_arrow.get(action, \" \")\n",
    "            row.append(symbol)\n",
    "        result.append(\" \".join(row))\n",
    "    \n",
    "    print(\"\\n\".join(result))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printResults(value_mat, policy_mat, count, gamma, isCatnipTerminal=False, algoType = 'std'):\n",
    "    if(algoType == 'std'):\n",
    "        print(\"######################### USING STANDARD VALUE ITERATION ALGO #########################\")\n",
    "    else:\n",
    "        print(\"######################### USING IN-PLACE VALUE ITERATION ALGO #########################\")\n",
    "    print(\"******** GAMMA ********\")\n",
    "    print(gamma)\n",
    "    np.set_printoptions(precision=4, suppress=True)\n",
    "    print(\"\\n******** FINAL VALUE FUNCTION ********\")\n",
    "    print(value_mat)\n",
    "    print(\"\\n******** FINAL POLICY ********\")\n",
    "    printPolicyMat(policy_mat, isCatnipTerminal)\n",
    "    print(\"\\n******** TOTAL ITERATIONS ********\")\n",
    "    print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################### USING STANDARD VALUE ITERATION ALGO #########################\n",
      "******** GAMMA ********\n",
      "0.925\n",
      "\n",
      "******** FINAL VALUE FUNCTION ********\n",
      "[[2.6638 2.9969 2.8117 3.6671 4.8497]\n",
      " [2.9713 3.5101 4.0819 4.8497 7.1648]\n",
      " [2.5936 0.     0.     0.     8.4687]\n",
      " [2.0992 1.0849 0.     8.6097 9.5269]\n",
      " [1.0849 4.9465 8.4687 9.5269 0.    ]]\n",
      "\n",
      "******** FINAL POLICY ********\n",
      "→ ↓ ← ↓ᴹ ↓\n",
      "→ → → → ↓\n",
      "↑ X X X ↓\n",
      "↑ ← X → ↓\n",
      "↑ →ᴹ → → G\n",
      "\n",
      "******** TOTAL ITERATIONS ********\n",
      "41\n"
     ]
    }
   ],
   "source": [
    "gamma = 0.925\n",
    "value_mat, policy_mat, count = runValueIterationAlgo(gamma)\n",
    "printResults(value_mat, policy_mat, count, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################### USING IN-PLACE VALUE ITERATION ALGO #########################\n",
      "******** GAMMA ********\n",
      "0.925\n",
      "\n",
      "******** FINAL VALUE FUNCTION ********\n",
      "[[2.6638 2.9969 2.8117 3.6671 4.8497]\n",
      " [2.9713 3.5101 4.0819 4.8497 7.1648]\n",
      " [2.5936 0.     0.     0.     8.4687]\n",
      " [2.0993 1.085  0.     8.6097 9.5269]\n",
      " [1.085  4.9466 8.4687 9.5269 0.    ]]\n",
      "\n",
      "******** FINAL POLICY ********\n",
      "→ ↓ ← ↓ᴹ ↓\n",
      "→ → → → ↓\n",
      "↑ X X X ↓\n",
      "↑ ← X → ↓\n",
      "↑ →ᴹ → → G\n",
      "\n",
      "******** TOTAL ITERATIONS ********\n",
      "29\n"
     ]
    }
   ],
   "source": [
    "gamma = 0.925\n",
    "value_mat, policy_mat, count = runValueIterationInPlace(gamma)\n",
    "printResults(value_mat, policy_mat, count, gamma, algoType='inplace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################### USING STANDARD VALUE ITERATION ALGO #########################\n",
      "******** GAMMA ********\n",
      "0.2\n",
      "\n",
      "******** FINAL VALUE FUNCTION ********\n",
      "[[-0.0625 -0.0625 -0.0625 -0.5445 -0.0579]\n",
      " [-0.0625 -0.0624 -0.0619 -0.058   0.0963]\n",
      " [-0.0625  0.      0.      0.      1.0304]\n",
      " [-0.0625 -0.0625  0.      1.1859  7.2754]\n",
      " [-0.0625 -0.5187  1.0304  7.2754  0.    ]]\n",
      "\n",
      "******** FINAL POLICY ********\n",
      "← ↓ ← ↓ᴹ →\n",
      "→ → → ↓ ↓\n",
      "← X X X ↓\n",
      "← ↑ X → ↓\n",
      "← ↑ᴹ → → G\n",
      "\n",
      "******** TOTAL ITERATIONS ********\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "gamma = 0.2\n",
    "value_mat, policy_mat, count = runValueIterationAlgo(gamma)\n",
    "printResults(value_mat, policy_mat, count, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################### USING IN-PLACE VALUE ITERATION ALGO #########################\n",
      "******** GAMMA ********\n",
      "0.2\n",
      "\n",
      "******** FINAL VALUE FUNCTION ********\n",
      "[[-0.0625 -0.0625 -0.0625 -0.5445 -0.0579]\n",
      " [-0.0625 -0.0624 -0.0619 -0.058   0.0963]\n",
      " [-0.0625  0.      0.      0.      1.0304]\n",
      " [-0.0625 -0.0625  0.      1.1859  7.2754]\n",
      " [-0.0625 -0.5187  1.0304  7.2754  0.    ]]\n",
      "\n",
      "******** FINAL POLICY ********\n",
      "← ↓ ← ↓ᴹ →\n",
      "→ → → ↓ ↓\n",
      "↑ X X X ↓\n",
      "← ↑ X → ↓\n",
      "← ↑ᴹ → → G\n",
      "\n",
      "******** TOTAL ITERATIONS ********\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "gamma = 0.2\n",
    "value_mat, policy_mat, count = runValueIterationInPlace(gamma)\n",
    "printResults(value_mat, policy_mat, count, gamma, algoType='inplace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################### USING STANDARD VALUE ITERATION ALGO #########################\n",
      "******** GAMMA ********\n",
      "0.925\n",
      "\n",
      "******** FINAL VALUE FUNCTION ********\n",
      "[[47.1488 47.9783 47.1002 39.7442 29.0421]\n",
      " [42.772  46.5915 42.4068 37.0317 32.1221]\n",
      " [38.2626  0.      0.      0.     28.7183]\n",
      " [33.3777 27.8861  0.     21.9072 25.167 ]\n",
      " [27.8861 23.7394 16.1924 18.1453  0.    ]]\n",
      "\n",
      "******** FINAL POLICY ********\n",
      "→ ↑ ← ←ᴹ ↓\n",
      "↑ ↑ ← ← ←\n",
      "↑ X X X ↑\n",
      "↑ ← X → ↑\n",
      "↑ ↑ᴹ → ↑ G\n",
      "\n",
      "******** TOTAL ITERATIONS ********\n",
      "136\n"
     ]
    }
   ],
   "source": [
    "gamma = 0.925\n",
    "isCatnip = True\n",
    "value_mat, policy_mat, count = runValueIterationAlgo(gamma, isCatnip=True, isCatnipTerminal=False, checkDiffRewards=(None, False))\n",
    "printResults(value_mat, policy_mat, count, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################### USING STANDARD VALUE ITERATION ALGO #########################\n",
      "******** GAMMA ********\n",
      "0.925\n",
      "\n",
      "******** FINAL VALUE FUNCTION ********\n",
      "[[4.7478 0.     4.7634 3.9275 4.8883]\n",
      " [4.2547 4.7036 4.3718 4.8883 7.1699]\n",
      " [3.7438 0.     0.     0.     8.4687]\n",
      " [3.098  1.8748 0.     8.6097 9.5269]\n",
      " [1.8748 5.0517 8.4687 9.5269 0.    ]]\n",
      "\n",
      "******** FINAL POLICY ********\n",
      "→ G ← ↓ᴹ ↓\n",
      "↑ ↑ → → ↓\n",
      "↑ X X X ↓\n",
      "↑ ← X → ↓\n",
      "↑ →ᴹ → → G\n",
      "\n",
      "******** TOTAL ITERATIONS ********\n",
      "24\n",
      "######################### USING STANDARD VALUE ITERATION ALGO #########################\n",
      "******** GAMMA ********\n",
      "0.93\n",
      "\n",
      "******** FINAL VALUE FUNCTION ********\n",
      "[[4.7617 0.     4.7938 4.093  5.0573]\n",
      " [4.2978 4.7351 4.5367 5.0573 7.3087]\n",
      " [3.8112 0.     0.     0.     8.5574]\n",
      " [3.185  1.9783 0.     8.691  9.5543]\n",
      " [1.9783 5.1773 8.5574 9.5543 0.    ]]\n",
      "\n",
      "******** FINAL POLICY ********\n",
      "→ G ← ↓ᴹ ↓\n",
      "↑ ↑ → → ↓\n",
      "↑ X X X ↓\n",
      "↑ ← X ↓ ↓\n",
      "↑ →ᴹ → → G\n",
      "\n",
      "******** TOTAL ITERATIONS ********\n",
      "24\n",
      "######################### USING STANDARD VALUE ITERATION ALGO #########################\n",
      "******** GAMMA ********\n",
      "0.94\n",
      "\n",
      "******** FINAL VALUE FUNCTION ********\n",
      "[[4.7902 0.     4.8578 4.4407 5.4091]\n",
      " [4.3856 4.8013 4.8833 5.4091 7.5942]\n",
      " [3.9494 0.     0.     0.     8.7372]\n",
      " [3.3658 2.1952 0.     8.8557 9.6099]\n",
      " [2.1952 5.4354 8.7372 9.6099 0.    ]]\n",
      "\n",
      "******** FINAL POLICY ********\n",
      "→ G ← ↓ᴹ ↓\n",
      "↑ ↑ → → ↓\n",
      "↑ X X X ↓\n",
      "↑ ← X ↓ ↓\n",
      "↑ →ᴹ → → G\n",
      "\n",
      "******** TOTAL ITERATIONS ********\n",
      "25\n",
      "######################### USING STANDARD VALUE ITERATION ALGO #########################\n",
      "******** GAMMA ********\n",
      "0.95\n",
      "\n",
      "******** FINAL VALUE FUNCTION ********\n",
      "[[4.8196 0.     4.9263 4.8115 5.7801]\n",
      " [4.4776 4.8851 5.2537 5.7801 7.8905]\n",
      " [4.0945 0.     0.     0.     8.9207]\n",
      " [3.5579 2.4272 0.     9.0233 9.6667]\n",
      " [2.4272 5.7032 8.9207 9.6667 0.    ]]\n",
      "\n",
      "******** FINAL POLICY ********\n",
      "→ G ← ↓ᴹ ↓\n",
      "↑ → → → ↓\n",
      "↑ X X X ↓\n",
      "↑ ← X ↓ ↓\n",
      "↑ →ᴹ → → G\n",
      "\n",
      "******** TOTAL ITERATIONS ********\n",
      "29\n"
     ]
    }
   ],
   "source": [
    "gammas = [0.925, 0.93, 0.94, 0.95]\n",
    "for gamma in gammas:\n",
    "    value_mat, policy_mat, count = runValueIterationAlgo(gamma, isCatnip=False, isCatnipTerminal=True, checkDiffRewards=(None, False))\n",
    "    printResults(value_mat, policy_mat, count, gamma, isCatnipTerminal=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################### USING STANDARD VALUE ITERATION ALGO #########################\n",
      "******** GAMMA ********\n",
      "0.925\n",
      "\n",
      "******** FINAL VALUE FUNCTION ********\n",
      "[[47.1488 47.9783 47.1002 39.7442 29.0421]\n",
      " [42.772  46.5915 42.4068 37.0317 32.1221]\n",
      " [38.2626  0.      0.      0.     28.7183]\n",
      " [33.3777 27.8861  0.     21.9072 25.167 ]\n",
      " [27.8861 23.7394 16.1924 18.1453  0.    ]]\n",
      "\n",
      "******** FINAL POLICY ********\n",
      "→ G ← ←ᴹ ↓\n",
      "↑ ↑ ← ← ←\n",
      "↑ X X X ↑\n",
      "↑ ← X → ↑\n",
      "↑ ↑ᴹ → ↑ G\n",
      "\n",
      "******** TOTAL ITERATIONS ********\n",
      "136\n",
      "\n",
      "******** REWARD ********\n",
      "5\n",
      "######################### USING STANDARD VALUE ITERATION ALGO #########################\n",
      "******** GAMMA ********\n",
      "0.925\n",
      "\n",
      "******** FINAL VALUE FUNCTION ********\n",
      "[[28.2115 28.7124 28.1821 22.9857 16.2921]\n",
      " [25.568  27.8749 25.3475 21.5475 18.5825]\n",
      " [22.8446  0.      0.      0.     16.5842]\n",
      " [19.8143 15.9766  0.     12.6904 14.5133]\n",
      " [15.9766 13.4314  9.8631 11.0829  0.    ]]\n",
      "\n",
      "******** FINAL POLICY ********\n",
      "→ G ← ←ᴹ ↓\n",
      "↑ ↑ ← ← ←\n",
      "↑ X X X ↑\n",
      "↑ ← X → ↑\n",
      "↑ ↑ᴹ → ↑ G\n",
      "\n",
      "******** TOTAL ITERATIONS ********\n",
      "129\n",
      "\n",
      "******** REWARD ********\n",
      "3\n",
      "######################### USING STANDARD VALUE ITERATION ALGO #########################\n",
      "******** GAMMA ********\n",
      "0.925\n",
      "\n",
      "******** FINAL VALUE FUNCTION ********\n",
      "[[27.2647 27.7492 27.2362 22.1478 15.6547]\n",
      " [24.7079 26.9391 24.4946 20.7733 17.9056]\n",
      " [22.0737  0.      0.      0.     15.9775]\n",
      " [19.1361 15.3812  0.     12.2296 13.9806]\n",
      " [15.3812 12.9161  9.5466 10.7298  0.    ]]\n",
      "\n",
      "******** FINAL POLICY ********\n",
      "→ G ← ←ᴹ ↓\n",
      "↑ ↑ ← ← ←\n",
      "↑ X X X ↑\n",
      "↑ ← X → ↑\n",
      "↑ ↑ᴹ → ↑ G\n",
      "\n",
      "******** TOTAL ITERATIONS ********\n",
      "129\n",
      "\n",
      "******** REWARD ********\n",
      "2.9\n",
      "######################### USING STANDARD VALUE ITERATION ALGO #########################\n",
      "******** GAMMA ********\n",
      "0.925\n",
      "\n",
      "******** FINAL VALUE FUNCTION ********\n",
      "[[26.3177 26.7859 26.2903 21.3099 15.0171]\n",
      " [23.8476 26.0032 23.6415 19.999  17.2285]\n",
      " [21.3028  0.      0.      0.     15.3708]\n",
      " [18.4579 14.7857  0.     11.7687 13.4479]\n",
      " [14.7857 12.4006  9.2301 10.3766  0.    ]]\n",
      "\n",
      "******** FINAL POLICY ********\n",
      "→ G ← ←ᴹ ↓\n",
      "↑ ↑ ← ← ←\n",
      "↑ X X X ↑\n",
      "↑ ← X → ↑\n",
      "↑ ↑ᴹ → ↑ G\n",
      "\n",
      "******** TOTAL ITERATIONS ********\n",
      "128\n",
      "\n",
      "******** REWARD ********\n",
      "2.8\n",
      "######################### USING STANDARD VALUE ITERATION ALGO #########################\n",
      "******** GAMMA ********\n",
      "0.925\n",
      "\n",
      "******** FINAL VALUE FUNCTION ********\n",
      "[[25.3709 25.8226 25.3444 20.472  14.3797]\n",
      " [22.9875 25.0674 22.7886 19.2249 16.5516]\n",
      " [20.5319  0.      0.      0.     14.7641]\n",
      " [17.7798 14.1903  0.     11.3079 12.9152]\n",
      " [14.1903 11.8853  8.9137 10.0235  0.    ]]\n",
      "\n",
      "******** FINAL POLICY ********\n",
      "→ G ← ←ᴹ ↓\n",
      "↑ ↑ ← ← ←\n",
      "↑ X X X ↑\n",
      "↑ ← X → ↑\n",
      "↑ ↑ᴹ → ↑ G\n",
      "\n",
      "******** TOTAL ITERATIONS ********\n",
      "128\n",
      "\n",
      "******** REWARD ********\n",
      "2.7\n",
      "######################### USING STANDARD VALUE ITERATION ALGO #########################\n",
      "******** GAMMA ********\n",
      "0.925\n",
      "\n",
      "******** FINAL VALUE FUNCTION ********\n",
      "[[24.4241 24.8594 24.3986 19.6341 13.7422]\n",
      " [22.1273 24.1317 21.9357 18.4507 15.8747]\n",
      " [19.7611  0.      0.      0.     14.1574]\n",
      " [17.102  13.5976  0.     10.8705 12.3857]\n",
      " [13.5976 11.3888  8.7386  9.828   0.    ]]\n",
      "\n",
      "******** FINAL POLICY ********\n",
      "→ G ← ←ᴹ ↓\n",
      "↑ ↑ ← ← ←\n",
      "↑ X X X ↑\n",
      "↑ ← X → ↑\n",
      "↑ ↑ᴹ → → G\n",
      "\n",
      "******** TOTAL ITERATIONS ********\n",
      "128\n",
      "\n",
      "******** REWARD ********\n",
      "2.6\n",
      "######################### USING STANDARD VALUE ITERATION ALGO #########################\n",
      "******** GAMMA ********\n",
      "0.925\n",
      "\n",
      "******** FINAL VALUE FUNCTION ********\n",
      "[[23.4772 23.896  23.4526 18.7961 13.1047]\n",
      " [21.2671 23.1958 21.0827 17.6765 15.1976]\n",
      " [18.9901  0.      0.      0.     13.5507]\n",
      " [16.4245 13.0074  0.     10.4539 11.8589]\n",
      " [13.0074 10.909   8.6888  9.7725  0.    ]]\n",
      "\n",
      "******** FINAL POLICY ********\n",
      "→ G ← ←ᴹ ↓\n",
      "↑ ↑ ← ← ←\n",
      "↑ X X X ↑\n",
      "↑ ← X → ↑\n",
      "↑ ↑ᴹ → → G\n",
      "\n",
      "******** TOTAL ITERATIONS ********\n",
      "127\n",
      "\n",
      "******** REWARD ********\n",
      "2.5\n"
     ]
    }
   ],
   "source": [
    "gamma = 0.925\n",
    "rewards = [5, 3, 2.9, 2.8, 2.7, 2.6, 2.5]\n",
    "for reward in rewards:\n",
    "    value_mat, policy_mat, count = runValueIterationAlgo(gamma, checkDiffRewards = (True, reward))\n",
    "    printResults(value_mat, policy_mat, count, gamma, isCatnipTerminal=True)\n",
    "    print(\"\\n******** REWARD ********\")\n",
    "    print(reward)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
